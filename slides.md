---
marp: true
theme: default
paginate: true
title: "От REST к MCP: как LLM меняют принципы проектирования API и архитектуры систем"
backgroundColor: white
lang: ru
style: |
section.lead h2 { text-align: center;}
---

<!-- _paginate: skip -->

# От REST к MCP: 
# как LLM меняют принципы проектирования API и архитектуры систем 
## Дмитрий Бондарев

---

# Agenda

1. Контекст: эволюция API и появление LLM‑агентов
2. Ограничения классических API в эпоху LLM
3. Model Context Protocol: архитектура и решения
4. Архитектурные сдвиги: от детерминизма к адаптивности
5. Практика внедрения: паттерны, безопасность, примеры

---

# 1. Контекст: эволюция API и появление LLM‑агентов

---

<!-- header: 1. Контекст: эволюция API и появление LLM‑агентов -->

## Что такое API?

**API (application programming interface)** — это формально описанный способ, по которому одна программа обращается к другой: какие операции доступны, какие параметры и форматы данных нужны, какие ошибки возможны и что гарантирует система.

Иными словами, это **контракт** между «поставщиком» функций/данных и их «потребителем», независимый от внутренней реализации.

---

## Краткая историческая справка об API

- **≈80 лет назад (≈1945–1951):** 
    - Появились первые библиотеки подпрограмм и модульный подход.

- **≈57 лет назад (1968):** 
    - В инженерных текстах закрепился термин **API** (*application program interface*)

- **≈25 лет назад (≈2000):** 
    - Началась эпоха **веб-API**: компании стали открывать HTTP-интерфейсы для внешних разработчиков.

---





## Современное состояние API (REST, GraphQL, gRPC)

---

## Сравнительная таблица: REST vs GraphQL vs gRPC

<div style="font-size: 20px;">

| Аспект | REST | GraphQL | gRPC |
|--------|------|---------|------|
| **Основной принцип** | Stateless, ресурсо-ориентированный | Гибкие запросы, одна точка входа | Типизированные контракты |
| **Главные проблемы** | Overfetching<br/> Underfetching | N+1 problem<br/> сложность кеширования | Жесткие контракты, сложность отладки |
| **Формат данных** | JSON/XML | JSON | ProtoBuf (бинарный) |
| **Типизация** | Слабая | Строгая схема | Строгая типизация |
| **Discovery механизм** | Статическая документация (OpenAPI) | Introspection запросы | Static protobuf схемы |
| **Состояние сессии** | Stateless по определению | Stateless (как правило) | Поддерживает streaming |
| **Гранулярность операций** | Мелкие ресурсо-ориентированные | Гибкая, но часто мелкозернистая | Может быть любой |
| **Адаптивность во время выполнения** | Жесткие контракты | Частично гибкие запросы | Жесткие контракты |
</div>

---

## Общая проблема: клиент должен заранее знать API

Во всех трех подходах клиент (программа) должен **заранее знать структуру API**:
- Какие эндпоинты доступны?
- Какие параметры принимают?
- Какой формат ответа ожидать?
- Какие ошибки возможны?

**Это создает жесткую связанность** между клиентом и сервером.

---

## Принцип HATEOAS: почему он не решает проблему полностью

**HATEOAS** (Hypermedia as the Engine of Application State) — принцип REST, где сервер включает в ответы ссылки на доступные действия.

<div style="font-size: 17px;">

```json
{
  "user": {
    "id": 123,
    "name": "Иван",
    "_links": {
      "self": "/users/123",
      "edit": "/users/123/edit",
      "delete": "/users/123"
    }
  }
}
```
</div>

<div style="font-size: 18px;">

### Почему не решает проблему:
- Клиент все равно должен понимать семантику ссылок
- Требует стандартизации форматов (HAL, JSON-LD)
- Сложность реализации на практике
- Не решает проблему динамического обнаружения возможностей
</div>

---



## Появление LLM-агентов

---

- **30 ноября 2022**: релиз ChatGPT (на базе GPT 3.5) в виде бесплатного research preview
- **Август 2025**: MAU ChatGPT ≈ 812 миллионов пользователей

- **2025 год** - назван годом Агентов 

> *"Если 2024 был годом LLM, то 2025 выглядит как год AI‑агентов"*  
> — The Guardian

---

## Что такое Agent и отличие его от Workflow

**Главная отличительная черта Агентов**: неопределенность вычислительного DAG. 
Решение об используемых сервисах происходит в процессе выполнения.

Иначе это **workflow** и проблема так остро не стоит. Прибить гвоздями и жестко определить вызовы 

### Статический DAG (workflow)

```mermaid
graph LR
    S[Start] --> T{Report Type}
    T --> F[Financial]
    T --> A[Activity]
    F --> GF[Generate Financial]
    A --> GA[Generate Activity]
    GF --> LF[LLM Summarize]
    GA --> LA[LLM Summarize]
    LF --> DF{Delivery}
    LA --> DA{Delivery}
    DF --> DFE[Email]
    DF --> DFD[Dashboard]
    DA --> DAE[Email]
    DA --> DAD[Dashboard]
    classDef fixed fill:#ffebee,stroke:#c62828,stroke-width:1px
    class S,T,F,A,GF,GA,LF,LA,DF,DA,DFE,DFD,DAE,DAD fixed
```

### Динамический DAG (agent)

```mermaid
graph LR
    A[LLM Agent] --> B{Runtime<br/>Decision}
    B -->|Tool A| TA[Call Tool A]
    B -->|Tool B| TB[Call Tool B]
    B -->|Tool C| TC[Call Tool C]
    TA --> U[Context Update]
    TB --> U
    TC --> U
    U --> B
    classDef adaptive fill:#e8f5e8,stroke:#2e7d32,stroke-width:1px
    class A,B,TA,TB,TC,U adaptive
```

---

## Какие же проблемы возникают при переходе на искользование Агентов как consumer?

---





---

## Зачем вообще агенты? Бизнес‑кейсы


**Когда агент уместен (vs классический workflow):**

*неопределённость пути*: последовательность шагов заранее не фиксируется, выбирается в процессе выполнения.

*экономия*: жёсткая автоматизация не окупается из‑за редкости или высокой вариативности сценариев.

*вариативности правил*: часто меняются данные, политики, приоритеты и стратегии.




<!-- header: 2. Ограничения классических API в эпоху LLM -->

# 2. Ограничения классических API в эпоху LLM

---

## Проблема MxN

![](attachments/MxN.png)

Когда растёт число инструментов (M) и LLM‑клиентов/агентов (N), связность «каждый с каждым» требует, чтобы каждый агент учился уникальным схемам инструментов и способам их вызова. Возникают M×N адаптеры промптов и форматов function‑calling, дублируются примеры использования, а поведение инструментов становится хрупким и неоднородным между моделями.

Без единой, понятной для LLM абстракции растут издержки на промпт‑инженерию и поддержку: разнится описание параметров и JSON‑форматы, меняются протоколы ошибок, требуется отдельная логика выбора инструмента и восстановления после неудачных вызовов. Тратится контекст на повторяющиеся описания и few‑shot примеры для каждой пары; смена модели или обновление инструмента ломает ранее стабильные цепочки.

<!-- _footer: https://huggingface.co/learn/mcp-course/unit1/key-concepts -->

---

## Проблема self-discovery: агент не знает доступные API

Классические API: программный клиент заранее знает доступные эндпоинты
- его запрограммировали разработчики

LLM-агенты: должны динамически обнаруживать возможности
- Нужен программный способ узнать доступные операции
- Описания должны быть понятными для LLM

---


## Проблема контекста 

<div style="font-size: 28px;">

Stateless накладывает дополнительную нагрузку на LLM агента и увеличивает вероятность ошибок и время выполнения операции

REST подход: каждый запрос содержит всю информацию
```
GET /api/tasks?user_id=123&status=active&page=1
GET /api/tasks?user_id=123&status=active&page=2
```
Разработчики могу реализовывать сессии, но это не включено в саму спецификацию.

Агентные сессии: длительные диалоги с контекстом
- "Покажи мои задачи" → "Отметь первую как выполненную" → "Создай похожую"
- Нужно помнить предыдущие действия и состояние
- Избыточность передачи контекста в каждом запросе
</div>

---

## Проблема гранулярности: мелкие операции vs человеческие задачи

Классические API: множество мелких операций
```
1. GET /user/123
2. GET /user/123/orders
3. POST /reports
4. PUT /reports/456
```

Человекочитаемые задачи: крупнозернистые операции
- "Подготовь отчет по клиенту"
- "Обнови статус заказа и уведоми клиента"
- Один инструмент = одна человеческая задача

---

## Проблема выбора инструментов среди большого числа опций
- Cognitive Load -  слишком много вариантов
- Качество выбора падает с ростом количества опций

![width:500](attachments/tool_selection_accuracy.png)

<!-- _footer: https://arxiv.org/abs/2310.03128 -->

---




<!-- header: 3. Model Context Protocol: архитектура и решения -->

# 3. Model Context Protocol: архитектура и решения

---

## Что такое MCP?

MCP (Model Context Protocol) — это открытый стандарт для подключения AI-ассистентов к источникам данных и инструментам.

- Универсальный адаптер: подобно USB-C для AI-приложений
- Стандартизированный способ подключения AI-моделей к различным сервисам
- Основан на JSON-RPC 2.0 протоколе

---

## Архитектура: Client-Host-Server

![width:750](attachments/mcp_architecture.png)

<!-- _footer: https://modelcontextprotocol.io/specification/2025-06-18/architecture -->

**Определения ролей (по спецификации MCP):**

- **Client**: компонент, который устанавливает соединение с MCP‑сервером, согласует возможности и вызывает предоставляемые сервером функции (tools, resources, prompts и др.). Может предоставлять серверу сервисы клиента, например `sampling` и уведомления.
- **Host**: хост‑приложение, внутри которого работает клиент и модель. Оркестрирует сессии, маршрутизирует запросы между моделью и несколькими серверами, изолирует их, контролирует доступ и хранит историю диалога.
- **Server**: самостоятельный процесс, публикующий возможности через MCP и обрабатывающий запросы клиента (вызовы инструментов, доступ к ресурсам, предоставление промптов). Не видит полный контекст диалога; вся координация идёт через хост.

См. спецификацию: [MCP Architecture](https://modelcontextprotocol.io/specification/2025-06-18/architecture).


---

## Ключевые принципы дизайна MCP

### 1. Серверы должны быть крайне простыми в разработке
- Хост-приложения берут на себя сложную оркестрацию
- Серверы фокусируются на конкретных, четко определенных возможностях
- Минимальные накладные расходы на реализацию

### 2. Серверы должны быть высоко композиционными
- Каждый сервер предоставляет изолированную функциональность
- Множественные серверы легко комбинируются
- Модульный дизайн поддерживает расширяемость

---

## Ключевые принципы дизайна MCP (продолжение)

<div style="font-size: 28px;">

### 3. Серверы не должны видеть полный контекст диалога
- Серверы получают только необходимую контекстную информацию
- Полная история разговора остается у хоста
- Каждое серверное соединение изолировано
- Взаимодействия между серверами контролируются хостом

### 4. Возможности могут добавляться итеративно
- Базовый протокол предоставляет минимально необходимую функциональность
- Дополнительные возможности согласовываются по мере необходимости
- Серверы и клиенты развиваются независимо
- Поддерживается обратная совместимость
</div>

---

## Capability Negotiation — согласование возможностей

- Клиенты и серверы **явно заявляют** о поддерживаемых функциях при инициализации
- Определяет, какие функции протокола доступны в течение сессии

**Серверы могут заявлять:**
- `resources` — поддержка ресурсов с подписками
- `tools` — возможность вызова инструментов
- `prompts` — предоставление шаблонов промптов

**Клиенты могут заявлять:**
- `sampling` — поддержка запросов на выборку от сервера
- `notifications` — обработка уведомлений

---

## Способы подключения MCP

### Локальное выполнение (STDIO)
- Прямое взаимодействие через стандартные потоки ввода/вывода
- Преимущества
  - Высокая производительность: нет сетевых задержек
  - Безопасность: выполнение в локальной среде

### Удаленное выполнение (HTTP + SSE)
- HTTP запросы для вызова инструментов
- Преимущества
  - Server-Sent Events (SSE) для двунаправленной связи
  - Масштабируемость. распределенная архитектура

---





## Как MCP решает проблемы классических API

---

## Решение проблемы MxN: M + N вместо M × N
![](attachments/M+N.png)


<!-- _footer: https://huggingface.co/learn/mcp-course/unit1/key-concepts -->

---

## Решение проблемы self-discovery: динамическое обнаружение инструментов
<div style="font-size: 22px;">

**Проблема:** LLM-агенты должны динамически обнаруживать возможности, но классические API не предоставляют программный способ узнать доступные операции.

**Решение MCP:** Runtime discovery через стандартизированные методы
</div>

<div style="font-size: 18px;">

```json
{ // Запрос списка доступных инструментов
  "jsonrpc": "2.0",
  "method": "tools/list",
  "id": 1
}

{ // Ответ с описанием инструментов
  "jsonrpc": "2.0",
  "result": {
    "tools": [
      {
        "name": "create_report",
        "description": "Создает отчет по клиенту",
        "inputSchema": { ... }
      }
    ]
  },
  "id": 1
}
```
</div>

---

## Решение проблемы контекста: от stateless к stateful-сессиям

Классические API (stateless): Stateless подход REST API накладывает дополнительную нагрузку на LLM агента, увеличивает вероятность ошибок и время выполнения.
```http
GET /api/tasks?user_id=123&status=active&filter=urgent
GET /api/tasks?user_id=123&status=active&filter=urgent&page=2
POST /api/tasks { "user_id": 123, "title": "New task", ... }
```

MCP (stateful): Встроенная поддержка контекстных сессий
```json
// Контекст сохраняется между вызовами
1. "Покажи мои срочные задачи"
2. "Отметь первую как выполненную" // знает о предыдущем списке
```

---

## Решение проблемы гранулярности: "one tool, one human task"

<div style="font-size: 28px;">

Классические API: множество мелких вызовов
```
1. GET /user/123
2. GET /user/123/orders  
3. GET /orders/456/items
4. POST /reports { user_data, order_data, items_data }
5. PUT /reports/789 { status: "completed" }
```

MCP: высокоуровневые инструменты, соответствующие человеческим задачам
```json
{
  "name": "generate_customer_report",
  "description": "Создает полный отчет по клиенту с историей заказов",
  "parameters": {
    "customer_id": 123,
    "period": "last_month"
  }
}
```
</div>

---

## Решение проблемы выбора инструментов: структурированная организация
<div style="font-size: 27px;">

**Проблема:** Cognitive Load - слишком много вариантов, качество выбора падает с ростом количества опций.

**Решение MCP:** 
- Иерархическая организация инструментов по серверам
- Семантические описания для LLM
- Возможность группировки по контексту использования

```json
// Инструменты организованы по серверам
{
  "filesystem_server": ["read_file", "write_file", "list_directory"],
  "database_server": ["query_db", "update_records"],
  "email_server": ["send_email", "create_draft"]
}
```
</div>

---


## Дополнительные преимущества: Двунаправленная связь. server-initiated messages

Серверы могут инициировать сообщения и уведомления
<div style="font-size: 18px;">

```json
// Сервер может отправить progress notification
{
  "jsonrpc": "2.0",
  "method": "notifications/progress",
  "params": {
    "progressToken": "report_generation_123",
    "progress": 75,
    "total": 100
  }
}

// Сервер может запросить дополнительную информацию
{
  "jsonrpc": "2.0", 
  "method": "sampling/createMessage",
  "params": {
    "messages": [
      {
        "role": "assistant",
        "content": "Для создания отчета нужна дополнительная информация. Какой период включить?"
      }
    ]
  }
}
```
</div>

---

## REST vs MCP

<div style="font-size: 19px;">

| Аспект | REST | MCP |
|---|---|---|
| **Основной принцип** | Stateless, ресурсо-ориентированный | Возможности, динамические DAG |
| **Главные проблемы** | Overfetching, Underfetching | Оркестрация (Host), политики/безопасность |
| **Формат данных** | JSON/XML | JSON‑RPC 2.0 |
| **Типизация** | Слабая | Схемы инструментов (`inputSchema`) |
| **Discovery механизм** | Статическая документация (OpenAPI) | Runtime discovery, capability negotiation |
| **Состояние сессии** | Stateless по определению | Stateful сессии (Host), прогресс/уведомления |
| **Гранулярность операций** | Мелкие ресурсо-ориентированные | One tool = human task |
| **Адаптивность во время выполнения** | Жесткие контракты | Адаптивный выбор инструментов |

</div>

---

<!-- header: 4. Архитектурные сдвиги: от детерминизма к адаптивности -->

# 4. Архитектурные сдвиги: от детерминизма к адаптивности
Практическая реализация — в разделе 5

---

## Принцип 1: От детерминированности к адаптивности

Классическая архитектура: статические графы выполнения

![width:800](attachments/statical_DAG.svg)


- **Предопределенные пути**: последовательность вызовов известна при разработке
- **Жесткая логика**: if/else ветвления в коде определяют поведение
- **Ошибки = баги**: неожиданный путь выполнения — ошибка разработчика

---

MCP архитектура: динамические графы выполнения



![](attachments/dynamic_DAG.svg)

- **Адаптивные пути**: LLM выбирает стратегию выполнения в runtime
- **Контекстные решения**: выбор инструментов зависит от текущей ситуации
- **Неопределенность как норма**: система должна адаптироваться к новым сценариям

**Ключевой сдвиг**: От программирования алгоритмов к программированию возможностей

---

## Принцип 2: От императивного к декларативному
Изменение роли разработчика



**Было**: Разработчик программирует точный алгоритм

<div style="font-size: 20px;">

```javascript
if (user.role === 'admin') {
  result = await getAdminData();
} else if (user.role === 'manager') {
  result = await getManagerData();
}
```

</div>

**Стало**: Разработчик определяет возможности и ограничения

<div style="font-size: 20px;">

```json
{
  "tools": ["get_admin_data", "get_manager_data"],
  "policies": {
    "get_admin_data": {"requires": ["admin_role"]},
    "get_manager_data": {"requires": ["manager_role"]}
  }
}
```

</div>

**Философия**: Вместо "как делать" определяем "что можно делать"

---

## Принцип 3: От stateless к контекстным сессиям

### Классический подход: каждый запрос независим
- REST принцип: вся информация в запросе
- Нет памяти о предыдущих взаимодействиях
- Масштабируемость через stateless-ность

### MCP подход: контекстные диалоги
- **Память сессии**: история взаимодействий
- **Длительные операции**: поддержка прогресса и обратной связи
- **Гибкое состояние**: от stateless инструментов до внешних хранилищ артефактов

**Компромисс**: Производительность диалога vs сложность масштабирования

---

## Принцип 4: От однонаправленной к двунаправленной связи

### Классические API: только request-response (в рамках спецификации)

![width:400](attachments/request-responce.svg)

---

### MCP: встроенная двунаправленность

![width:400](attachments/bidirectional.svg)


**Результат**: Более богатое взаимодействие, приближенное к человеческому диалогу

---

## Принцип 5: Новая модель распределения ответственности

<div style="font-size: 25px;">

| Было (классические API) | Стало (MCP) |
|--------------------------|-------------|
| **Детальный контроль**<br/>Разработчик программирует каждый шаг | **Определение политик**<br/>Разработчик задает правила игры |
| **Статические контракты**<br/>Жесткие схемы API | **Динамические возможности**<br/>API описывает "что можно" и "когда можно" |
| **Централизованная логика**<br/>Вся логика в одном месте | **Распределенный интеллект**<br/>Решения на разных уровнях системы |
| **Предсказуемость**<br/>Все пути выполнения известны | **Адаптивность**<br/>Система справляется с новыми сценариями |

</div>

---

## Архитектурная метафора: от заводского конвейера к живому организму

### Классические системы = Заводской конвейер

![width:1000](attachments/classical_workflow.svg)


- Четкая последовательность операций
- Каждый элемент выполняет строго определенную функцию
- Отклонения = поломки

---

### MCP системы = Живой организм  


![width:800](attachments/life_graph.svg)


- Адаптация к изменяющимся условиям
- Различные органы (MCP серверы) взаимодействуют через нервную систему (Host)
- Способность к обучению и эволюции

**Это требует нового мышления от архитекторов и разработчиков**

---

<!-- header: 5. Практика внедрения: паттерны, безопасность, примеры -->

# 5. Практика внедрения: паттерны, безопасность, примеры

---

## AI Gateway как центральный компонент
  - Отдельный слой для приёма MCP-трафика (пример — Azure API Management)
  - Лимиты, валидация аргументов, мониторинг и аудит
  - Контроль политик и защита от prompt injection

---

## Архитектурные паттерны:
  - MCP-сервер как фасад для микросервисов
  - Оборачивание нескольких REST-вызовов в один высокоуровневый инструмент
  - Проблемы транзакционности в новой архитектуре

---

## Наблюдаемость и надежность:
  - Tracing агентных вызовов
  - Fallback-стратегии при сбоях LLM
  - Timeout-ы и circuit breakers для агентов

---

## Вызовы и риски

---

## Специфические угрозы AI-эпохи
  - Prompt injection атаки
  - "Фальшивые" инструменты-двойники
  - Утечки данных через объединение инструментов

---

## Изменения в модели безопасности
  - От доверия разработчику к контролю агента
  - Система разрешений на уровне инструментов
  - Моделирование поведения непредсказуемого клиента

---

## Стратегии защиты
  - Изоляция локальных vs удаленных MCP-серверов
  - Аудит и логирование агентной активности
  - Политики доступа и ограничения

---

## Практические bootstrap примеры

---

## Код на Go: MCP server

---

## Код на Python: MCP server
